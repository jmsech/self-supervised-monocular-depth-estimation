{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "loss_vis",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNFuUDkgBy4l"
      },
      "source": [
        "import torch\n",
        "import sys\n",
        "sys.path.append(\"/home/mjfleming99/monocular-depth-estimation/\")\n",
        "sys.path.append(\"/home/justinsech/monocular-depth-estimation/\")\n",
        "\n",
        "from Dataloader import Kittiloader\n",
        "from dataset import DataGenerator\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "import torchvision"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iIgtn9wB2Al"
      },
      "source": [
        "data_path = \"/home/mjfleming99/monocular-depth-estimation/dataset\"\n",
        "test_data = DataGenerator(data_path, phase='test', splits=\"eigen\").create_data(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jhUdxEeB3dY"
      },
      "source": [
        "#116 is best scene for vis\n",
        "with torch.no_grad():\n",
        "    for i, data in enumerate(test_data):\n",
        "        if i == 116:\n",
        "            a = data\n",
        "            break\n",
        "    \n",
        "left_img = a['left_img'].cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4N7XxwjB89b"
      },
      "source": [
        "model = torch.load(\"/home/mjfleming99/monocular-depth-estimation/repeatable_fast_epoch_3\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hdWFesaB9gn"
      },
      "source": [
        "def get_depth_map(disp, H, W):\n",
        "\tresized_disp = F.interpolate(disp.unsqueeze(0).unsqueeze(0), size=(H, W), mode=\"bilinear\").squeeze()\n",
        "\n",
        "\tdepth_est = SCALE_FACTOR / resized_disp\n",
        "\n",
        "\treturn depth_est\n",
        "def crop(depth_map):\n",
        "\t# We copied the crops floats for evaluation from the origonal implementation.\n",
        "\t# These crops are somewhat arbitrary, so coping them is the only way\n",
        "\t# to get a good evaluation metric.\n",
        "\n",
        "\th, w = depth_map.shape\n",
        "\treturn depth_map[int(0.3924324 * h):int(0.91351351 * h), int(0.0359477 * w):int(0.96405229 * w)]\n",
        "\n",
        "def crop_img(depth_map):\n",
        "\t# We copied the crops floats for evaluation from the origonal implementation.\n",
        "\t# These crops are somewhat arbitrary, so coping them is the only way\n",
        "\t# to get a good evaluation metric.\n",
        "\n",
        "\t_, h, w = depth_map.shape\n",
        "\treturn depth_map[:,int(0.3924324 * h):int(0.91351351 * h), int(0.0359477 * w):int(0.96405229 * w)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLAY_jD9B-19"
      },
      "source": [
        "img = a['left_img']\n",
        "disp1, disp2, disp3, disp4 = model.forward(left_img)\n",
        "disp = disp1[:, 0, :, :].squeeze()\n",
        "gt = a['depth_interp'].squeeze()\n",
        "\n",
        "print(img.shape, disp.shape, gt.shape)\n",
        "\n",
        "img = F.interpolate(img, size=gt.shape, mode=\"bilinear\").squeeze()\n",
        "disp = F.interpolate(disp.unsqueeze(0).unsqueeze(0), size=gt.shape, mode=\"bilinear\").squeeze()\n",
        "\n",
        "print(img.shape, disp.shape, gt.shape)\n",
        "\n",
        "img = crop_img(img).detach().cpu()\n",
        "disp = crop(disp).detach().cpu()\n",
        "gt = crop(gt).detach().cpu()\n",
        "print(img.shape, disp.shape, gt.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oViADa7CAos"
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(15,10))\n",
        "vmax = np.percentile(disp, 95)\n",
        "plt.imshow(disp , cmap=\"magma\", vmax=vmax);\n",
        "plt.title(\"Disparity Estimate\");\n",
        "plt.setp(ax.get_xticklabels(), visible=False)\n",
        "plt.setp(ax.get_yticklabels(), visible=False)\n",
        "ax.tick_params(axis='both', which='both', length=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "144fGZOiCCit"
      },
      "source": [
        "SCALE_FACTOR = 5.4\n",
        "MIN_DEPTH = 1e-3\n",
        "MAX_DEPTH = 80\n",
        "gt = a['depth_interp'].squeeze().cpu()\n",
        "disp = disp1[:, 0, :, :].squeeze().cpu()\n",
        "pred_depth_map = get_depth_map(disp, *gt.shape)\n",
        "\n",
        "cropped_pred = crop(pred_depth_map)\n",
        "cropped_truth = crop(gt)\n",
        "\n",
        "cropped_truth[cropped_truth > MAX_DEPTH] = MAX_DEPTH\n",
        "cropped_truth[cropped_truth < MIN_DEPTH] = MIN_DEPTH\n",
        "\n",
        "ratio = torch.median(cropped_truth) / torch.median(cropped_pred)\n",
        "cropped_scaled_pred = ratio * cropped_pred\n",
        "\n",
        "# cropped_pred[cropped_pred > MAX_DEPTH] = MAX_DEPTH\n",
        "# cropped_pred[cropped_pred < MIN_DEPTH] = MIN_DEPTH\n",
        "\n",
        "\n",
        "cropped_scaled_pred[cropped_scaled_pred > MAX_DEPTH] = MAX_DEPTH\n",
        "cropped_scaled_pred[cropped_scaled_pred < MIN_DEPTH] = MIN_DEPTH\n",
        "\n",
        "\n",
        "cropped_truth = cropped_truth.detach().cpu()\n",
        "cropped_pred =cropped_pred.detach().cpu()\n",
        "cropped_scaled_pred = cropped_scaled_pred.detach().cpu()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRkr2aeHCGR8"
      },
      "source": [
        "fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(5,10))\n",
        "axes[0].hist(cropped_pred);\n",
        "axes[0].set_xlabel('Depth Prediction (meters)')\n",
        "axes[0].set_ylabel('Pixel Counts')\n",
        "axes[0].set_title('Unscaled Depth Predictions')\n",
        "\n",
        "axes[1].hist(cropped_scaled_pred);\n",
        "axes[1].set_xlabel('Depth Prediction (meters)')\n",
        "axes[1].set_ylabel('Pixel Counts')\n",
        "axes[1].set_title('Median Scaled Depth Predictions')\n",
        "\n",
        "axes[2].hist(gt.squeeze());\n",
        "axes[2].set_xlabel('Depth Prediction (meters)');\n",
        "axes[2].set_ylabel('Pixel Counts');\n",
        "axes[2].set_title('True Depth');\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANdVecQaCJPa"
      },
      "source": [
        "fig, axes = plt.subplots(nrows=6, ncols=2, figsize=(15,10))\n",
        "\n",
        "axes[0][0].imshow(img.permute(1,2,0));\n",
        "axes[0][0].set_title(\"Original Left Img\");\n",
        "\n",
        "vmax = np.percentile(disp, 95)\n",
        "axes[0][1].imshow(disp , cmap=\"magma\", vmax=vmax);\n",
        "axes[0][1].set_title(\"Disparity Estimate\");\n",
        "\n",
        "axes[1][0].imshow(cropped_scaled_pred, cmap=\"magma\");\n",
        "axes[1][0].set_title(\"Depth Estimate\");\n",
        "\n",
        "axes[1][1].imshow(cropped_truth, cmap=\"magma\");\n",
        "axes[1][1].set_title(\"True Depth\");\n",
        "\n",
        "pred = cropped_scaled_pred\n",
        "target = cropped_truth\n",
        "\n",
        "abs_rel = torch.abs(target - pred) / target\n",
        "sq_rel = torch.abs(target - pred) ** 2 / target\n",
        "rmse = torch.abs(target - pred)\n",
        "rmse_log = torch.abs(torch.log(target) - torch.log(pred)) ** 0.5\n",
        "\n",
        "\n",
        "delta = torch.max(pred/target, target/pred)\n",
        "metric1 = (delta > 1.25).float()\n",
        "metric2 = (delta > 1.25 ** 2).float()\n",
        "metric3 = (delta > 1.25 ** 3).float()\n",
        "\n",
        "\n",
        "axes[2][0].imshow(abs_rel, cmap=\"seismic\");\n",
        "axes[2][0].set_title(\"Abs Rel\");\n",
        "\n",
        "axes[2][1].imshow(sq_rel, cmap=\"seismic\");\n",
        "axes[2][1].set_title(\"Sq Rel\");\n",
        "\n",
        "axes[3][0].imshow(rmse, cmap=\"seismic\");\n",
        "axes[3][0].set_title(\"RMSE\");\n",
        "\n",
        "axes[3][1].imshow(rmse_log, cmap=\"seismic\");\n",
        "axes[3][1].set_title(\"RMSE Log\");\n",
        "\n",
        "\n",
        "axes[4][0].imshow(metric1, cmap=\"seismic\");\n",
        "axes[4][0].set_title(\"δ<1.25\");\n",
        "\n",
        "axes[4][1].imshow(metric2, cmap=\"seismic\");\n",
        "axes[4][1].set_title(f\"δ<1.25\\N{SUPERSCRIPT TWO}\");\n",
        "\n",
        "axes[5][0].imshow(metric3, cmap=\"seismic\");\n",
        "axes[5][0].set_title(f\"δ<1.25\\N{SUPERSCRIPT THREE}\");\n",
        "\n",
        "for item in axes:\n",
        "    for i in item:\n",
        "        plt.setp(i.get_xticklabels(), visible=False)\n",
        "        plt.setp(i.get_yticklabels(), visible=False)\n",
        "        i.tick_params(axis='both', which='both', length=0)\n",
        "\n",
        "\n",
        "fig.delaxes(axes[5][1])\n",
        "plt.tight_layout()\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}